The following script is suited for RStudio and was sorted from https://robwschlegel.github.io/heatwaveR/index.html

# Following heatwave.R code
install.packages("heatwaveR")
head(heatwaveR::sst_WA)

# Load libraries
library(tidyverse)
library(heatwaveR)

# Detect the events in a time series
ts <- ts2clm(sst_WA, climatologyPeriod = c("1982-01-01", "2011-12-31"))
mhw <- detect_event(ts)

# View just a few metrics
mhw$event %>% 
  dplyr::ungroup() %>%
  dplyr::select(event_no, duration, date_start, date_peak, intensity_max, intensity_cumulative) %>% 
  dplyr::arrange(-intensity_max) %>% 
  head(5)

mhw$event %>% 
  dplyr::ungroup() %>%
  dplyr::select(event_no, duration, date_start, date_peak, intensity_max, duration) %>% 
  dplyr::arrange(-intensity_max) %>% 
  head(5)

event_line(mhw, spread = 180, metric = "intensity_max", 
           start_date = "1982-01-01", end_date = "2014-12-31")

lolli_plot(mhw, metric = "intensity_max")

lolli_plot(mhw, metric = "duration")

lolli_plot(mhw, metric = "intensity_cumulative")

# Select the region of the time series of interest
mhw2 <- mhw$climatology %>% 
  slice(10580:10720)

#ggplot(mhw2, aes(x = t, y = temp, y2 = thresh)) +
  geom_flame() +
  geom_text(aes(x = as.Date("2011-02-25"), y = 25.8, label = "the Destroyer\nof Kelps"))

ggplot(mhw$event, aes(x = date_start, y = intensity_max)) +
  geom_lolli(colour = "salmon", colour_n = "red", n = 3) +
  geom_text(colour = "black", aes(x = as.Date("2006-08-01"), y = 5,
                                  label = "The marine heatwaves\nTend to be left skewed in a\nGiven time series")) +
  labs(y = expression(paste("Max. intensity [", degree, "C]")), x = NULL)

# It is necessary to give geom_flame() at least one row on either side of 
# the event in order to calculate the polygon corners smoothly
#mhw_top <- mhw2 %>% 
  slice(5:111)

#ggplot(data = mhw2, aes(x = t)) +
  geom_flame(aes(y = temp, y2 = thresh, fill = "all"), show.legend = T) +
  geom_flame(data = mhw_top, aes(y = temp, y2 = thresh, fill = "top"),  show.legend = T) +
  geom_line(aes(y = temp, colour = "temp")) +
  geom_line(aes(y = thresh, colour = "thresh"), size = 1.0) +
  geom_line(aes(y = seas, colour = "seas"), size = 1.2) +
  scale_colour_manual(name = "Line Colour",
                      values = c("temp" = "black", 
                                 "thresh" =  "forestgreen", 
                                 "seas" = "grey80")) +
  scale_fill_manual(name = "Event Colour", 
                    values = c("all" = "salmon", 
                               "top" = "red")) +
  scale_x_date(date_labels = "%b %Y") +
  guides(colour = guide_legend(override.aes = list(fill = NA))) +
  labs(y = expression(paste("Temperature [", degree, "C]")), x = NULL)

mhw3 <- mhw$climatology %>% 
  slice(850:950)

#ggplot(mhw3, aes(x = t, y = temp, y2 = thresh)) +
  geom_flame(fill = "black", alpha = 0.5) +
  # Note the use of n = 5 and n_gap = 2 below
  geom_flame(n = 5, n_gap = 2, fill = "red", alpha = 0.5) +
  ylim(c(22, 25)) +
  geom_text(colour = "black", aes(x = as.Date("1984-05-16"), y = 24.5,
                                  label = "heat\n\n\n\n\nspike"))

ggplot(mhw$event, aes(x = date_peak, y = intensity_max)) +
  geom_lolli(colour = "firebrick") +
  labs(x = "Peak Date", 
       y = expression(paste("Max. intensity [", degree, "C]")), x = NULL) +
  theme_linedraw()

# The two packages we will need
# NB: The packages only need to be installed from GitHub once
# devtools::install_github("tidyverse/tidyverse")
# devtools::install_github("ropensci/rerddap")

# Load the packages once they have been downloaded and installed
install.packages("tidyverse")
install.packages("rerddap")
library(tidyverse)
library(rerddap)

# The information for the NOAA OISST data
rerddap::info(datasetid = "ncdc_oisst_v2_avhrr_by_time_zlev_lat_lon", url = "https://www.ncei.noaa.gov/erddap/")

# This function expects the user to provide it with a start and end date
# It then downloads and prepares the data
OISST_sub <- function(time_df){
  oisst_res <- griddap(x = "ncdc_oisst_v2_avhrr_by_time_zlev_lat_lon", 
                       url = "https://www.ncei.noaa.gov/erddap/", 
                       time = c(time_df$start, time_df$end), 
                       depth = c(0, 0),
                       latitude = c(-40, -35),
                       longitude = c(15, 21),
                       fields = "sst")$data %>% 
    mutate(time = as.Date(str_remove(time, "T00:00:00Z"))) %>% 
    dplyr::rename(t = time, temp = sst) %>% 
    select(lon, lat, t, temp) %>% 
    na.omit()
}

dl_years <- data.frame(date_index = 1:5,
                       start = as.Date(c("1982-01-01", "1990-01-01", 
                                         "1998-01-01", "2006-01-01", "2014-01-01")),
                       end = as.Date(c("1989-12-31", "1997-12-31", 
                                       "2005-12-31", "2013-12-31", "2018-12-31")))

# Download all of the data with one nested request
# The time this takes will vary greatly based on connection speed
system.time(
  OISST_data <- dl_years %>% 
    group_by(date_index) %>% 
    group_modify(~OISST_sub(.x)) %>% 
    ungroup() %>% 
    select(lon, lat, t, temp)
) 
# 921 seconds, ~184 seconds per batch

# Save the data as an .Rda file as it has a much better compression rate than .RData
saveRDS(OISST_data, file = "~/Desktop/OISST_vignette.Rda")

library(tidyverse)
library(heatwaveR)

OISST <- read_rds("~/Desktop/OISST_vignette.Rda")

event_only <- function(df){
  # First calculate the climatologies
  clim <- ts2clm(data = df, climatologyPeriod = c("1982-01-01", "2011-01-01"))
  # Then the events
  event <- detect_event(data = clim)
  # Return only the event metric dataframe of results
  return(event$event)
}
system.time(
  # First we start by chosing the 'OISST' dataframe
  MHW_dplyr <- OISST %>% 
    # Then we group the data by the 'lon' and 'lat' columns
    group_by(lon, lat) %>% 
    # Then we run our MHW calculating function on each group
    group_modify(~event_only(.x))
) # 214 seconds

# The 'dplyr' wrapper function to pass to 'plyr'
dplyr_wraper <- function(file_name){
  MHW_dplyr <- readRDS(file_name) %>% 
    group_by(lon, lat) %>% 
    group_modify(~event_only(.x))
}

# Create a vector of the files we want to use
OISST_files <- dir("~/Desktop", pattern = "OISST_lon_*", full.names = T)

# Use 'plyr' technique to run 'dplyr' technique with multiple cores
system.time(
  MHW_result <- plyr::ldply(OISST_files, .fun = dplyr_wraper, .parallel = T)
)# 128

# summarise the number of unique longitude, latitude and year combination:
event_freq <- MHW_result %>% 
  mutate(year = lubridate::year(date_start)) %>% 
  group_by(lon, lat, year) %>% 
  summarise(n = n())
head(event_freq)

# create complete grid for merging with:
sst_grid <- OISST %>% 
  select(lon, lat, t) %>% 
  mutate(t = lubridate::year(t)) %>% 
  dplyr::rename(year = t) %>% 
  distinct()

# and merge:
OISST_n <- left_join(sst_grid, event_freq, by = c("lon", "lat", "year")) %>% 
  mutate(n = ifelse(is.na(n), 0, n))


OISST <- read_rds("~/Desktop/OISST_vignette.Rda")

event_only <- function(df){
  # First calculate the climatologies
  clim <- ts2clm(data = df, climatologyPeriod = c("1982-01-01", "2011-01-01"))
  # Then the events
  event <- detect_event(data = clim)
  # Return only the event metric dataframe of results
  return(event$event)
}

system.time(
  # First we start by chosing the 'OISST' dataframe
  MHW_dplyr <- OISST %>% 
    # Then we group the data by the 'lon' and 'lat' columns
    group_by(lon, lat) %>% 
    # Then we run our MHW calculating function on each group
    group_modify(~event_only(.x))
) # 214 seconds

# NB: One should never use ALL available cores, save at least 1 for other essential tasks
# The computer I'm writing this vignette on has 4 cores, so I use 3 here
install.packages("doMC")
library(doMC)
registerDoMC(cores = 3)

system.time(
  MHW_plyr <- plyr::ddply(.data = OISST, .variables = c("lon", "lat"), .fun = event_only, .parallel = TRUE)
) # 129 seconds

for(i in 1:length(unique(OISST$lon))){
  OISST_sub <- OISST %>% 
    filter(lon == unique(lon)[i])
  saveRDS(object = OISST_sub, file = paste0("~/Desktop/OISST_lon_",i,".Rda"))
}

# The 'dplyr' wrapper function to pass to 'plyr'
dplyr_wraper <- function(file_name){
  MHW_dplyr <- readRDS(file_name) %>% 
    group_by(lon, lat) %>% 
    group_modify(~event_only(.x))
}

# Create a vector of the files we want to use
OISST_files <- dir("~/Desktop", pattern = "OISST_lon_*", full.names = T)

# Use 'plyr' technique to run 'dplyr' technique with multiple cores
system.time(
  MHW_result <- plyr::ldply(OISST_files, .fun = dplyr_wraper, .parallel = T)
)# 128

# summarise the number of unique longitude, latitude and year combination:
event_freq <- MHW_result %>% 
  mutate(year = lubridate::year(date_start)) %>% 
  group_by(lon, lat, year) %>% 
  summarise(n = n())
head(event_freq)

# create complete grid for merging with:
sst_grid <- OISST %>% 
  select(lon, lat, t) %>% 
  mutate(t = lubridate::year(t)) %>% 
  dplyr::rename(year = t) %>% 
  distinct()

# and merge:
OISST_n <- left_join(sst_grid, event_freq, by = c("lon", "lat", "year")) %>% 
  mutate(n = ifelse(is.na(n), 0, n))

lin_fun <- function(ev) {
  mod1 <- glm(n ~ year, family = poisson(link = "log"), data = ev)
  # extract slope coefficient and its p-value
  tr <- data.frame(slope = summary(mod1)$coefficients[2,1],
                   p = summary(mod1)$coefficients[2,4])
  return(tr)
}

OISST_nTrend <- OISST_n %>% 
  group_by(lon, lat) %>% 
  group_modify(~lin_fun(.x)) %>% 
  mutate(pval = cut(p, breaks = c(0, 0.001, 0.01, 0.05, 1)))
head(OISST_nTrend)

OISST_nTrend <- plyr::ddply(OISST_n, c("lon", "lat"), lin_fun, .parallel = T)
OISST_nTrend$pval <- cut(OISST_nTrend$p, breaks = c(0, 0.001, 0.01, 0.05, 1))
head(OISST_nTrend)

# The base map
install.packages("maps")
library(maps)
map_base <- ggplot2::fortify(maps::map(fill = TRUE, plot = FALSE)) %>% 
  dplyr::rename(lon = long)

map_slope <- ggplot(OISST_nTrend, aes(x = lon, y = lat)) +
  geom_rect(size = 0.2, fill = NA,
            aes(xmin = lon - 0.1, xmax = lon + 0.1, ymin = lat - 0.1, ymax = lat + 0.1,
                colour = pval)) +
  geom_raster(aes(fill = slope), interpolate = FALSE, alpha = 0.9) +
  scale_fill_gradient2(name = "count/year (slope)", high = "red", mid = "white",
                       low = "darkblue", midpoint = 0,
                       guide = guide_colourbar(direction = "horizontal",
                                               title.position = "top")) +
  scale_colour_manual(breaks = c("(0,0.001]", "(0.001,0.01]", "(0.01,0.05]", "(0.05,1]"),
                      values = c("firebrick1", "firebrick2", "firebrick3", "white"),
                      name = "p-value", guide = FALSE) +
  geom_polygon(data = map_base, aes(group = group), 
               colour = NA, fill = "grey80") +
  coord_fixed(ratio = 1, xlim = c(13.0, 23.0), ylim = c(-33, -42), expand = TRUE) +
  labs(x = "", y = "") +
  theme_bw() +
  theme(legend.position = "bottom")

map_p <- ggplot(OISST_nTrend, aes(x = lon, y = lat)) +
  geom_raster(aes(fill = pval), interpolate = FALSE) +
  scale_fill_manual(breaks = c("(0,0.001]", "(0.001,0.01]", "(0.01,0.05]",
                               "(0.05,0.1]", "(0.1,0.5]", "(0.5,1]"),
                    values = c("black", "grey20", "grey40",
                               "grey80", "grey90", "white"),
                    name = "p-value",
                    guide = guide_legend(direction = "horizontal",
                                         title.position = "top")) +
  geom_polygon(data = map_base, aes(group = group), 
               colour = NA, fill = "grey80") +
  coord_fixed(ratio = 1, xlim = c(13.0, 23.0), ylim = c(-33, -42), expand = TRUE) +
  labs(x = "", y = "") +
  theme_bw() +
  theme(legend.position = "bottom")

install.packages("ggpubr")
library(ggpubr)

map_both <- ggpubr::ggarrange(map_slope, map_p, align = "hv")
map_both
